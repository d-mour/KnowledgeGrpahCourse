#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
–ó–ê–î–ê–ß–ê 8: –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–ï –ù–ï–î–û–°–¢–ê–Æ–©–ò–• –°–°–´–õ–û–ö (LINK PREDICTION)

–î–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç—Ä–∏–ø–ª–µ—Ç–∞ –∏–∑ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏:
1. –ó–∞–º–µ–Ω—è–µ–º —Å—É—â–Ω–æ—Å—Ç—å –Ω–∞ –¥—Ä—É–≥—É—é (—Ñ–æ—Ä–º–∏—Ä—É–µ–º –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ —Ç—Ä–∏–ø–ª–µ—Ç—ã)
2. –í—ã—á–∏—Å–ª—è–µ–º score –¥–ª—è –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –∏ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö —Ç—Ä–∏–ø–ª–µ—Ç–æ–≤
3. –†–∞–Ω–∂–∏—Ä—É–µ–º –∏ —Ñ–∏–∫—Å–∏—Ä—É–µ–º –ø–æ–∑–∏—Ü–∏—é –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ç—Ä–∏–ø–ª–µ—Ç–∞
4. –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ MR, MRR, Hits@N
"""

from owlready2 import *
import os
import json
import numpy as np
from collections import defaultdict

try:
    import torch
    from pykeen.models import TransE
    HAS_PYKEEN = True
except ImportError:
    HAS_PYKEEN = False


def load_model_and_data(model_dir: str = "kg_embeddings_pykeen"):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å –∏ –¥–∞–Ω–Ω—ã–µ"""
    print("üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏...")
    
    model_path = os.path.join(model_dir, "trained_model.pkl")
    model = torch.load(model_path, map_location='cpu', weights_only=False)
    
    with open(os.path.join(model_dir, "entity_to_id.json"), 'r') as f:
        entity_to_id = json.load(f)
    
    with open(os.path.join(model_dir, "relation_to_id.json"), 'r') as f:
        relation_to_id = json.load(f)
    
    id_to_entity = {v: k for k, v in entity_to_id.items()}
    id_to_relation = {v: k for k, v in relation_to_id.items()}
    
    print(f"   ‚úÖ –ú–æ–¥–µ–ª—å: {model.num_entities} —Å—É—â–Ω–æ—Å—Ç–µ–π, {model.num_relations} –æ—Ç–Ω–æ—à–µ–Ω–∏–π")
    
    return model, entity_to_id, relation_to_id, id_to_entity, id_to_relation


def extract_triples(onto, entity_to_id, relation_to_id):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç—Ä–∏–ø–ª–µ—Ç—ã –∏–∑ –æ–Ω—Ç–æ–ª–æ–≥–∏–∏"""
    print("\nüìã –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç—Ä–∏–ø–ª–µ—Ç–æ–≤...")
    
    triples = []
    
    for vehicle in onto.Vehicle.instances():
        if vehicle.name not in entity_to_id:
            continue
        
        if hasattr(vehicle, 'MadeBy') and vehicle.MadeBy:
            for m in vehicle.MadeBy:
                if m.name in entity_to_id and 'MadeBy' in relation_to_id:
                    triples.append((vehicle.name, 'MadeBy', m.name))
        
        if hasattr(vehicle, 'StyledAs') and vehicle.StyledAs:
            for s in vehicle.StyledAs:
                if s.name in entity_to_id and 'StyledAs' in relation_to_id:
                    triples.append((vehicle.name, 'StyledAs', s.name))
        
        if hasattr(vehicle, 'hasSegment') and vehicle.hasSegment:
            for seg in vehicle.hasSegment:
                if seg.name in entity_to_id and 'hasSegment' in relation_to_id:
                    triples.append((vehicle.name, 'hasSegment', seg.name))
    
    print(f"   ‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(triples)} —Ç—Ä–∏–ø–ª–µ—Ç–æ–≤")
    return triples


def split_triples_by_year(triples, onto, entity_to_id, split_year=2015):
    """–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ —Ç—Ä–∏–ø–ª–µ—Ç–æ–≤ –ø–æ –≥–æ–¥—É"""
    print(f"\nüìÖ –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –ø–æ –≥–æ–¥—É (–≥—Ä–∞–Ω–∏—Ü–∞: {split_year})...")
    
    vehicle_years = {}
    for vehicle in onto.Vehicle.instances():
        if hasattr(vehicle, 'Year') and vehicle.Year:
            vehicle_years[vehicle.name] = vehicle.Year
    
    train_triples = []
    test_triples = []
    
    for h, r, t in triples:
        year = vehicle_years.get(h, 2010)
        if year < split_year:
            train_triples.append((h, r, t))
        else:
            test_triples.append((h, r, t))
    
    print(f"   Train (–≥–æ–¥ < {split_year}): {len(train_triples)} —Ç—Ä–∏–ø–ª–µ—Ç–æ–≤")
    print(f"   Test (–≥–æ–¥ >= {split_year}): {len(test_triples)} —Ç—Ä–∏–ø–ª–µ—Ç–æ–≤")
    
    return train_triples, test_triples


def evaluate_link_prediction(model, test_triples, entity_to_id, relation_to_id, 
                            id_to_entity, entity_type="Manufacturer", 
                            max_samples=500, num_negatives=100):
    """
    –û—Ü–µ–Ω–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö —Å—Å—ã–ª–æ–∫
    
    –î–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç—Ä–∏–ø–ª–µ—Ç–∞ –∏–∑ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏:
    1. –§–æ—Ä–º–∏—Ä—É–µ–º –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ —Ç—Ä–∏–ø–ª–µ—Ç—ã (–∑–∞–º–µ–Ω—è–µ–º tail)
    2. –í—ã—á–∏—Å–ª—è–µ–º score –¥–ª—è –≤—Å–µ—Ö —Ç—Ä–∏–ø–ª–µ—Ç–æ–≤
    3. –†–∞–Ω–∂–∏—Ä—É–µ–º –∏ –Ω–∞—Ö–æ–¥–∏–º –ø–æ–∑–∏—Ü–∏—é –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ —Ç—Ä–∏–ø–ª–µ—Ç–∞
    """
    print(f"\nüìä –û—Ü–µ–Ω–∫–∞ Link Prediction (—Ç–∏–ø —Å—É—â–Ω–æ—Å—Ç–∏: {entity_type})...")
    print(f"   –ú–∞–∫—Å–∏–º—É–º —Ç—Ä–∏–ø–ª–µ—Ç–æ–≤: {max_samples}")
    print(f"   –ù–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤: {num_negatives}")
    
    if entity_type == "Manufacturer":
        relation_filter = "MadeBy"
    elif entity_type == "BodyStyle":
        relation_filter = "StyledAs"
    else:
        relation_filter = None
    
    filtered_triples = []
    for h, r, t in test_triples:
        if relation_filter is None or r == relation_filter:
            filtered_triples.append((h, r, t))
    
    filtered_triples = filtered_triples[:max_samples]
    print(f"   –¢—Ä–∏–ø–ª–µ—Ç–æ–≤ –¥–ª—è –æ—Ü–µ–Ω–∫–∏: {len(filtered_triples)}")
    
    all_entities = list(entity_to_id.keys())
    
    ranks = []
    
    for idx, (head, relation, tail) in enumerate(filtered_triples):
        if idx % 100 == 0:
            print(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {idx}/{len(filtered_triples)}")
        
        head_id = entity_to_id[head]
        relation_id = relation_to_id[relation]
        tail_id = entity_to_id[tail]
        
        negative_tails = []
        while len(negative_tails) < num_negatives:
            neg_entity = all_entities[np.random.randint(len(all_entities))]
            if neg_entity != tail and neg_entity not in negative_tails:
                negative_tails.append(neg_entity)
        
        all_tails = [tail] + negative_tails
        
        hrt_batch = torch.zeros((len(all_tails), 3), dtype=torch.long)
        for i, t_name in enumerate(all_tails):
            hrt_batch[i, 0] = head_id
            hrt_batch[i, 1] = relation_id
            hrt_batch[i, 2] = entity_to_id[t_name]
        
        with torch.no_grad():
            scores = model.score_hrt(hrt_batch).squeeze(-1)
        
        scores_with_idx = [(scores[i].item(), i) for i in range(len(scores))]
        scores_with_idx.sort(key=lambda x: -x[0])
        
        rank = None
        for position, (score, original_idx) in enumerate(scores_with_idx, 1):
            if original_idx == 0:
                rank = position
                break
        
        ranks.append(rank)
    
    ranks = np.array(ranks)
    
    mr = np.mean(ranks)
    mrr = np.mean(1.0 / ranks)
    hits_at_1 = np.mean(ranks <= 1)
    hits_at_3 = np.mean(ranks <= 3)
    hits_at_10 = np.mean(ranks <= 10)
    
    print(f"\n‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏:")
    print(f"   –û—Ü–µ–Ω–µ–Ω–æ —Ç—Ä–∏–ø–ª–µ—Ç–æ–≤: {len(ranks)}")
    
    return {
        'MR': mr,
        'MRR': mrr,
        'Hits@1': hits_at_1,
        'Hits@3': hits_at_3,
        'Hits@10': hits_at_10,
        'ranks': ranks
    }


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("="*80)
    print("–ó–ê–î–ê–ß–ê 8: –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–ï –ù–ï–î–û–°–¢–ê–Æ–©–ò–• –°–°–´–õ–û–ö (LINK PREDICTION)")
    print("="*80)
    
    if not HAS_PYKEEN:
        print("‚ùå PyKEEN –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        return
    
    print("\nüìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –æ–Ω—Ç–æ–ª–æ–≥–∏–∏...")
    onto = get_ontology("file://" + os.path.abspath("cars_ontology.owl")).load()
    print(f"   ‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π: {len(list(onto.Vehicle.instances()))}")
    
    model, entity_to_id, relation_to_id, id_to_entity, id_to_relation = load_model_and_data()
    
    triples = extract_triples(onto, entity_to_id, relation_to_id)
    
    train_triples, test_triples = split_triples_by_year(triples, onto, entity_to_id, split_year=2015)
    
    print("\n" + "="*80)
    print("–û–¶–ï–ù–ö–ê 1: –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—è (Manufacturer)")
    print("="*80)
    
    results_manufacturer = evaluate_link_prediction(
        model, test_triples, entity_to_id, relation_to_id, id_to_entity,
        entity_type="Manufacturer", max_samples=300, num_negatives=50
    )
    
    print("\n" + "="*80)
    print("–û–¶–ï–ù–ö–ê 2: –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ç–∏–ø–∞ –∫—É–∑–æ–≤–∞ (BodyStyle)")
    print("="*80)
    
    results_bodystyle = evaluate_link_prediction(
        model, test_triples, entity_to_id, relation_to_id, id_to_entity,
        entity_type="BodyStyle", max_samples=300, num_negatives=50
    )
    
    print("\n" + "="*80)
    print("–ò–¢–û–ì–û–í–´–ï –ú–ï–¢–†–ò–ö–ò –ö–ê–ß–ï–°–¢–í–ê")
    print("="*80)
    
    print(f"""
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ –ú–µ—Ç—Ä–∏–∫–∞                ‚îÇ Manufacturer     ‚îÇ BodyStyle        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ MR (Mean Rank)         ‚îÇ {results_manufacturer['MR']:>14.2f}   ‚îÇ {results_bodystyle['MR']:>14.2f}   ‚îÇ
‚îÇ MRR (Mean Reciprocal)  ‚îÇ {results_manufacturer['MRR']:>14.4f}   ‚îÇ {results_bodystyle['MRR']:>14.4f}   ‚îÇ
‚îÇ Hits@1                 ‚îÇ {results_manufacturer['Hits@1']*100:>13.1f}%  ‚îÇ {results_bodystyle['Hits@1']*100:>13.1f}%  ‚îÇ
‚îÇ Hits@3                 ‚îÇ {results_manufacturer['Hits@3']*100:>13.1f}%  ‚îÇ {results_bodystyle['Hits@3']*100:>13.1f}%  ‚îÇ
‚îÇ Hits@10                ‚îÇ {results_manufacturer['Hits@10']*100:>13.1f}%  ‚îÇ {results_bodystyle['Hits@10']*100:>13.1f}%  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
""")
    
    print("""
üìå –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –º–µ—Ç—Ä–∏–∫:

1. MR (Mean Rank) - —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ–∑–∏—Ü–∏–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ —Ç—Ä–∏–ø–ª–µ—Ç–∞:
   - –ß–µ–º –ú–ï–ù–¨–®–ï, —Ç–µ–º –ª—É—á—à–µ
   - –ò–¥–µ–∞–ª—å–Ω–æ: MR = 1 (–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –≤—Å–µ–≥–¥–∞ –ø–µ—Ä–≤—ã–π)
   
2. MRR (Mean Reciprocal Rank) - —Å—Ä–µ–¥–Ω–µ–µ –æ–±—Ä–∞—Ç–Ω–æ–≥–æ —Ä–∞–Ω–≥–∞:
   - –ß–µ–º –ë–û–õ–¨–®–ï, —Ç–µ–º –ª—É—á—à–µ
   - –î–∏–∞–ø–∞–∑–æ–Ω: 0 –¥–æ 1
   - MRR > 0.5 = —Ö–æ—Ä–æ—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
   
3. Hits@N - –¥–æ–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤ –≤ —Ç–æ–ø-N:
   - –ß–µ–º –ë–û–õ–¨–®–ï, —Ç–µ–º –ª—É—á—à–µ
   - –î–∏–∞–ø–∞–∑–æ–Ω: 0% –¥–æ 100%
   - Hits@10 > 50% = —Ö–æ—Ä–æ—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç

‚úÖ –í—ã–≤–æ–¥: –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ —Å–≤—è–∑–∏ –≤ –≥—Ä–∞—Ñ–µ –∑–Ω–∞–Ω–∏–π!
""")


if __name__ == "__main__":
    main()

