#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Knowledge Graph Embeddings Ñ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸ÐµÐ¼ PyKEEN

PyKEEN - ÑÑ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚Ð½Ð°Ñ Ð±Ð¸Ð±Ð»Ð¸Ð¾Ñ‚ÐµÐºÐ° Ð´Ð»Ñ KGE, ÑƒÐ¿Ð¾Ð¼ÑÐ½ÑƒÑ‚Ð°Ñ Ð² Ð»ÐµÐºÑ†Ð¸Ð¸.
Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½ÑƒÑŽ Ñ€ÐµÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸ÑŽ TransE Ð¸ Ð´Ñ€ÑƒÐ³Ð¸Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹.
"""

from owlready2 import *
import json
import os
from typing import List, Tuple, Optional

# Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð¾Ð½Ñ‚Ð¾Ð»Ð¾Ð³Ð¸ÑŽ Ð³Ð»Ð¾Ð±Ð°Ð»ÑŒÐ½Ð¾
onto = get_ontology("file://cars_ontology.owl").load()

try:
    from pykeen.triples import TriplesFactory
    from pykeen.pipeline import pipeline
    from pykeen.models import TransE
    HAS_PYKEEN = True
except ImportError:
    HAS_PYKEEN = False
    print("âš ï¸  PyKEEN Ð½Ðµ ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½. Ð£ÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚Ðµ: pip install pykeen")


def extract_triples_from_ontology() -> List[Tuple[str, str, str]]:
    """Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÑ‚ Ñ‚Ñ€Ð¸Ð¿Ð»ÐµÑ‚Ñ‹ Ð¸Ð· Ð¾Ð½Ñ‚Ð¾Ð»Ð¾Ð³Ð¸Ð¸"""
    print("="*80)
    print("Ð˜Ð—Ð’Ð›Ð•Ð§Ð•ÐÐ˜Ð• Ð¢Ð Ð˜ÐŸÐ›Ð•Ð¢ÐžÐ’ Ð˜Ð— Ð“Ð ÐÐ¤Ð Ð—ÐÐÐÐ˜Ð™")
    print("="*80)
    
    triples = []
    
    # Vehicle --MadeBy--> Manufacturer
    print("\n1. Ð˜Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ðµ ÑÐ²ÑÐ·ÐµÐ¹ Vehicle --MadeBy--> Manufacturer...")
    for vehicle in onto.Vehicle.instances():
        if hasattr(vehicle, 'MadeBy') and vehicle.MadeBy:
            for manufacturer in vehicle.MadeBy:
                triples.append((vehicle.name, 'MadeBy', manufacturer.name))
    
    # Vehicle --StyledAs--> BodyStyle
    print("2. Ð˜Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ðµ ÑÐ²ÑÐ·ÐµÐ¹ Vehicle --StyledAs--> BodyStyle...")
    for vehicle in onto.Vehicle.instances():
        if hasattr(vehicle, 'StyledAs') and vehicle.StyledAs:
            for body_style in vehicle.StyledAs:
                triples.append((vehicle.name, 'StyledAs', body_style.name))
    
    # Vehicle --hasSegment--> MarketSegment
    print("3. Ð˜Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ðµ ÑÐ²ÑÐ·ÐµÐ¹ Vehicle --hasSegment--> MarketSegment...")
    for vehicle in onto.Vehicle.instances():
        if hasattr(vehicle, 'hasSegment') and vehicle.hasSegment:
            for segment in vehicle.hasSegment:
                triples.append((vehicle.name, 'hasSegment', segment.name))
    
    # Vehicle --hasEngine--> Engine
    print("4. Ð˜Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ðµ ÑÐ²ÑÐ·ÐµÐ¹ Vehicle --hasEngine--> Engine...")
    for vehicle in onto.Vehicle.instances():
        if hasattr(vehicle, 'hasEngine') and vehicle.hasEngine:
            for engine in vehicle.hasEngine:
                triples.append((vehicle.name, 'hasEngine', engine.name))
    
    # Vehicle --hasTransmission--> Transmission
    print("5. Ð˜Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ðµ ÑÐ²ÑÐ·ÐµÐ¹ Vehicle --hasTransmission--> Transmission...")
    for vehicle in onto.Vehicle.instances():
        if hasattr(vehicle, 'hasTransmission') and vehicle.hasTransmission:
            for transmission in vehicle.hasTransmission:
                triples.append((vehicle.name, 'hasTransmission', transmission.name))
    
    # Manufacturer --WhereIs--> Country
    print("6. Ð˜Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ðµ ÑÐ²ÑÐ·ÐµÐ¹ Manufacturer --WhereIs--> Country...")
    for manufacturer in onto.Manufacturer.instances():
        if hasattr(manufacturer, 'WhereIs') and manufacturer.WhereIs:
            for country in manufacturer.WhereIs:
                triples.append((manufacturer.name, 'WhereIs', country.name))
    
    print(f"\nâœ… Ð˜Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¾ Ñ‚Ñ€Ð¸Ð¿Ð»ÐµÑ‚Ð¾Ð²: {len(triples)}")
    
    return triples


def create_kg_embeddings_pykeen(limit: Optional[int] = None,
                                embedding_dim: int = 64,
                                num_epochs: int = 100,
                                model_name: str = "TransE"):
    """
    Ð¡ÐžÐ—Ð”ÐÐÐ˜Ð• KNOWLEDGE GRAPH EMBEDDINGS Ð¡ Ð˜Ð¡ÐŸÐžÐ›Ð¬Ð—ÐžÐ’ÐÐÐ˜Ð•Ðœ PyKEEN
    
    PyKEEN - ÑÑ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚Ð½Ð°Ñ Ð±Ð¸Ð±Ð»Ð¸Ð¾Ñ‚ÐµÐºÐ°, ÑƒÐ¿Ð¾Ð¼ÑÐ½ÑƒÑ‚Ð°Ñ Ð² Ð»ÐµÐºÑ†Ð¸Ð¸.
    Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½ÑƒÑŽ Ñ€ÐµÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸ÑŽ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ KGE.
    """
    if not HAS_PYKEEN:
        print("\nâŒ PyKEEN Ð½Ðµ ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½!")
        print("   Ð£ÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚Ðµ: pip install pykeen")
        return None
    
    print("="*80)
    print("Ð¡ÐžÐ—Ð”ÐÐÐ˜Ð• KNOWLEDGE GRAPH EMBEDDINGS (PyKEEN)")
    print("="*80)
    
    # Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ Ñ‚Ñ€Ð¸Ð¿Ð»ÐµÑ‚Ñ‹
    triples = extract_triples_from_ontology()
    
    if limit:
        triples = triples[:limit]
        print(f"\nâš ï¸  ÐžÐ³Ñ€Ð°Ð½Ð¸Ñ‡ÐµÐ½Ð¸Ðµ: Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð¿ÐµÑ€Ð²Ñ‹Ðµ {limit} Ñ‚Ñ€Ð¸Ð¿Ð»ÐµÑ‚Ð¾Ð²")
    
    if len(triples) == 0:
        print("âŒ Ð¢Ñ€Ð¸Ð¿Ð»ÐµÑ‚Ñ‹ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ñ‹!")
        return None
    
    # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ñ‚Ñ€Ð¸Ð¿Ð»ÐµÑ‚Ñ‹ Ð²Ð¾ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ð¹ Ñ„Ð°Ð¹Ð» Ð´Ð»Ñ PyKEEN
    temp_file = "temp_triples.tsv"
    with open(temp_file, 'w', encoding='utf-8') as f:
        for h, r, t in triples:
            f.write(f"{h}\t{r}\t{t}\n")
    
    print(f"\nâœ… Ð¢Ñ€Ð¸Ð¿Ð»ÐµÑ‚Ñ‹ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ñ‹ Ð² {temp_file}")
    
    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ TriplesFactory Ð¸Ð· Ñ„Ð°Ð¹Ð»Ð°
    print("\nðŸ“‚ Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ñ‚Ñ€Ð¸Ð¿Ð»ÐµÑ‚Ð¾Ð² Ð² PyKEEN...")
    triples_factory = TriplesFactory.from_path(temp_file)
    
    print(f"   Ð¡ÑƒÑ‰Ð½Ð¾ÑÑ‚ÐµÐ¹: {triples_factory.num_entities}")
    print(f"   ÐžÑ‚Ð½Ð¾ÑˆÐµÐ½Ð¸Ð¹: {triples_factory.num_relations}")
    print(f"   Ð¢Ñ€Ð¸Ð¿Ð»ÐµÑ‚Ð¾Ð²: {triples_factory.num_triples}")
    
    # Ð Ð°Ð·Ð´ÐµÐ»ÑÐµÐ¼ Ð½Ð° train/test (80/20)
    training, testing = triples_factory.split([0.8, 0.2])
    
    print(f"\nðŸ“Š Ð Ð°Ð·Ð´ÐµÐ»ÐµÐ½Ð¸Ðµ Ð´Ð°Ð½Ð½Ñ‹Ñ…:")
    print(f"   Train: {training.num_triples} Ñ‚Ñ€Ð¸Ð¿Ð»ÐµÑ‚Ð¾Ð²")
    print(f"   Test: {testing.num_triples} Ñ‚Ñ€Ð¸Ð¿Ð»ÐµÑ‚Ð¾Ð²")
    
    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ pipeline Ð´Ð»Ñ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ
    print(f"\nðŸš€ Ð—Ð°Ð¿ÑƒÑÐº Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð¼Ð¾Ð´ÐµÐ»Ð¸ {model_name}...")
    print(f"   Ð­Ð¿Ð¾Ñ…: {num_epochs}")
    print(f"   Ð Ð°Ð·Ð¼ÐµÑ€Ð½Ð¾ÑÑ‚ÑŒ embeddings: {embedding_dim}")
    
    result = pipeline(
        training=training,
        testing=testing,
        model=model_name,
        model_kwargs=dict(embedding_dim=embedding_dim),
        training_kwargs=dict(num_epochs=num_epochs),
        random_seed=42,
        device='cpu',  # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ CPU (Ð¼Ð¾Ð¶Ð½Ð¾ 'cuda' ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ GPU)
    )
    
    print(f"\nâœ… ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¾!")
    
    # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹
    output_dir = "kg_embeddings_pykeen"
    os.makedirs(output_dir, exist_ok=True)
    
    # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð¼Ð¾Ð´ÐµÐ»ÑŒ
    result.save_to_directory(output_dir)
    
    print(f"\nâœ… ÐœÐ¾Ð´ÐµÐ»ÑŒ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð° Ð²: {output_dir}/")
    
    # Ð’Ñ‹Ð²Ð¾Ð´Ð¸Ð¼ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸
    print(f"\nðŸ“Š ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð°:")
    try:
        # PyKEEN Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ð² metric_results
        if hasattr(result, 'metric_results'):
            metrics = result.metric_results.to_dict()
            if 'both' in metrics and 'realistic' in metrics['both']:
                realistic = metrics['both']['realistic']
                mr = realistic.get('arithmetic_mean_rank', 'N/A')
                mrr = realistic.get('inverse_harmonic_mean_rank', 'N/A')
                hits10 = realistic.get('hits_at_10', 'N/A')
                print(f"   MR (Mean Rank): {mr}")
                print(f"   MRR: {mrr}")
                print(f"   Hits@10: {hits10}")
            else:
                print(f"   ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹ Ð² result.metric_results")
        else:
            print(f"   ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ð±ÑƒÐ´ÑƒÑ‚ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ñ‹ Ð² results.json")
    except Exception as e:
        print(f"   âš ï¸  ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸: {e}")
        print(f"   ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ñ‹ Ð² {output_dir}/results.json")
    
    # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð¼Ð°Ð¿Ð¿Ð¸Ð½Ð³Ð¸
    # PyKEEN Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ ÑÐ²Ð¾Ð¸ Ð¸Ð½Ð´ÐµÐºÑÑ‹, Ð½ÑƒÐ¶Ð½Ð¾ ÑÐ¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ Ð¸Ñ…
    entity_to_id = {}
    relation_to_id = {}
    
    # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð¼Ð°Ð¿Ð¿Ð¸Ð½Ð³Ð¸ Ð¸Ð· triples_factory
    for idx, entity in enumerate(triples_factory.entity_to_id.keys()):
        entity_to_id[entity] = idx
    
    for idx, rel in enumerate(triples_factory.relation_to_id.keys()):
        relation_to_id[rel] = idx
    
    with open(os.path.join(output_dir, "entity_to_id.json"), 'w', encoding='utf-8') as f:
        json.dump(entity_to_id, f, ensure_ascii=False, indent=2)
    
    with open(os.path.join(output_dir, "relation_to_id.json"), 'w', encoding='utf-8') as f:
        json.dump(relation_to_id, f, ensure_ascii=False, indent=2)
    
    # Ð¢Ð°ÐºÐ¶Ðµ ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ triples_factory Ð´Ð»Ñ ÑƒÐ´Ð¾Ð±ÑÑ‚Ð²Ð°
    try:
        training.save(os.path.join(output_dir, "training_triples"))
    except:
        # Ð•ÑÐ»Ð¸ Ð¼ÐµÑ‚Ð¾Ð´ save Ð½Ðµ Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚, ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð²Ñ€ÑƒÑ‡Ð½ÑƒÑŽ
        pass
    
    # Ð£Ð´Ð°Ð»ÑÐµÐ¼ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ð¹ Ñ„Ð°Ð¹Ð»
    if os.path.exists(temp_file):
        os.remove(temp_file)
    
    print(f"\nâœ… Ð’ÑÐµ Ð³Ð¾Ñ‚Ð¾Ð²Ð¾! Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ:")
    print(f"   from pykeen.models import TransE")
    print(f"   model = TransE.from_pretrained('{output_dir}')")
    
    return result


if __name__ == "__main__":
    import sys
    
    limit = None
    embedding_dim = 64
    num_epochs = 100
    model_name = "TransE"
    
    if len(sys.argv) > 1:
        if '--limit' in sys.argv:
            limit_idx = sys.argv.index('--limit')
            if limit_idx + 1 < len(sys.argv):
                limit = int(sys.argv[limit_idx + 1])
        
        if '--dim' in sys.argv:
            dim_idx = sys.argv.index('--dim')
            if dim_idx + 1 < len(sys.argv):
                embedding_dim = int(sys.argv[dim_idx + 1])
        
        if '--epochs' in sys.argv:
            epochs_idx = sys.argv.index('--epochs')
            if epochs_idx + 1 < len(sys.argv):
                num_epochs = int(sys.argv[epochs_idx + 1])
        
        if '--model' in sys.argv:
            model_idx = sys.argv.index('--model')
            if model_idx + 1 < len(sys.argv):
                model_name = sys.argv[model_idx + 1]
    
    create_kg_embeddings_pykeen(
        limit=limit,
        embedding_dim=embedding_dim,
        num_epochs=num_epochs,
        model_name=model_name
    )

