# Что такое Embeddings и как они работают

## Простое объяснение

**Embedding** (встраивание) - это способ превратить сложный объект (например, автомобиль) в набор чисел (вектор), который сохраняет информацию о его характеристиках.

### Аналогия

Представьте, что каждый автомобиль - это точка на карте:
- Похожие автомобили находятся близко друг к другу
- Разные автомобили - далеко друг от друга
- Мы можем измерить "расстояние" между автомобилями

Embedding - это координаты этой точки на многомерной "карте" автомобилей.

## Что мы создаем?

### 1. Векторное представление каждого автомобиля

Для каждого автомобиля мы создаем **вектор из 64 чисел** (можно настроить), который кодирует:

```
Автомобиль: BMW 3 Series 2016
Embedding: [0.23, -0.45, 0.67, 0.12, -0.89, ..., 0.34]
           ↑     ↑      ↑     ↑      ↑          ↑
          64 числа, каждое кодирует какую-то характеристику
```

### 2. Что кодируется в этих числах?

Мы берем все характеристики автомобиля:
- **Числовые:** год, мощность, расход топлива, цена, рейтинг безопасности
- **Категориальные:** производитель, тип кузова, тип привода
- **Вычисляемые:** надежность, семейность, экономичность, спортивность

И превращаем их в один вектор, где:
- Похожие автомобили имеют похожие векторы
- Разные автомобили имеют разные векторы

### 3. Пример

```
BMW 3 Series 2016 (спортивный седан):
Embedding: [0.2, 0.8, 0.3, 0.1, ...]

BMW 3 Series 2017 (похожий):
Embedding: [0.21, 0.79, 0.31, 0.11, ...]  ← очень похожий вектор!

Toyota Prius 2016 (экономичный):
Embedding: [-0.5, -0.3, 0.9, 0.8, ...]    ← совсем другой вектор
```

## Как это работает?

### Шаг 1: Извлечение признаков

Для каждого автомобиля собираем все данные:
```python
BMW_3_Series_2016 = {
    'year': 2016,
    'engine_hp': 248,
    'city_mpg': 23.0,
    'crash_rating': 5,
    'reliability': 8.0,
    'sportiness_level': 'High',
    ...
}
```

### Шаг 2: Нормализация

Приводим все к одному масштабу:
- Год: 2016 → нормализованное значение
- Мощность: 248 л.с. → нормализованное значение
- Цена: $38,750 → нормализованное значение
- И т.д.

### Шаг 3: Создание вектора

Объединяем все нормализованные значения в один вектор:
```
[нормализованный_год, нормализованная_мощность, нормализованная_цена, ...]
```

### Шаг 4: Снижение размерности (PCA/SVD)

Сжимаем вектор до 64 чисел, сохраняя важную информацию:
```
23 признака → 64 измерения (embedding)
```

## Что мы будем искать?

### 1. Поиск похожих автомобилей

**Вопрос:** "Найди автомобили похожие на BMW 3 Series 2016"

**Как работает:**
1. Берем embedding BMW 3 Series 2016
2. Сравниваем его со всеми другими embeddings
3. Находим те, у которых векторы наиболее похожи (близки)
4. Возвращаем топ-10 самых похожих

**Результат:**
- BMW 3 Series 2017 (очень похож)
- BMW 3 Series 2015 (похож)
- Audi A4 2016 (похож по характеристикам)
- Mercedes C-Class 2016 (похож)

### 2. Поиск по описанию

**Вопрос:** "Нужен экономичный семейный автомобиль с высоким рейтингом безопасности"

**Как работает:**
1. Создаем "идеальный" embedding на основе запроса:
   ```python
   query_embedding = {
       'city_mpg': 30.0,      # высокий расход
       'crash_rating': 5,     # максимальный рейтинг
       'trunk_volume': 20.0,  # большой багажник
       'family_score': 8.0    # высокая семейность
   }
   ```
2. Превращаем запрос в вектор (так же, как автомобили)
3. Ищем автомобили с наиболее похожими векторами
4. Возвращаем результаты

**Результат:**
- Toyota Camry 2016 (экономичный, безопасный, семейный)
- Honda Accord 2017 (похожие характеристики)
- Subaru Outback 2016 (безопасный, семейный)

### 3. Рекомендации

**Вопрос:** "Мне нравится этот автомобиль, что еще посоветуете?"

**Как работает:**
1. Берем embedding понравившегося автомобиля
2. Находим похожие по всем характеристикам
3. Предлагаем альтернативы

## Преимущества перед SPARQL

### SPARQL (точный поиск):
```
"Найди автомобили где:
- city_mpg >= 25
- crash_rating = 5
- price <= 30000"
```
**Проблема:** Если нет точного совпадения - ничего не найдется

### Embeddings (семантический поиск):
```
"Найди автомобили похожие на:
- экономичные (city_mpg ~25)
- безопасные (crash_rating ~5)
- недорогие (price ~30000)"
```
**Преимущество:** Найдет даже если параметры немного отличаются

## Визуализация

Представьте 3D пространство:

```
                    Спортивные
                        ↑
                        |
    Экономичные ←───────┼───────→ Премиум
                        |
                        ↓
                    Семейные
```

Каждый автомобиль - точка в этом пространстве:
- **BMW M3** - в углу "Спортивные"
- **Toyota Prius** - в углу "Экономичные"
- **BMW 7 Series** - в углу "Премиум"
- **Honda Odyssey** - в углу "Семейные"

Embedding - это координаты этой точки!

## Практический пример

### Сценарий 1: Поиск альтернативы

**Пользователь:** "Хочу BMW 3 Series, но дешевле"

**Embedding поиск:**
1. Находит BMW 3 Series в базе
2. Ищет похожие автомобили с меньшей ценой
3. Находит: Audi A4, Mercedes C-Class, Lexus IS

### Сценарий 2: Нечеткий запрос

**Пользователь:** "Нужна машина для семьи, чтобы была надежная и не очень дорогая"

**Embedding поиск:**
1. Создает embedding запроса (семейность + надежность + бюджет)
2. Ищет автомобили с похожими embeddings
3. Находит: Toyota Camry, Honda Accord, Subaru Legacy

### Сценарий 3: Рекомендации

**Пользователь:** "Смотрю на Ford Mustang"

**Embedding поиск:**
1. Находит Ford Mustang
2. Ищет похожие спортивные автомобили
3. Рекомендует: Chevrolet Camaro, Dodge Challenger, BMW 2 Series

## Технические детали

### Размерность embedding

- **64 измерения** - хороший баланс между точностью и скоростью
- Можно увеличить до 128-256 для большей точности
- Можно уменьшить до 32 для экономии памяти

### Метрика сходства

Используем **косинусное сходство**:
- Измеряет угол между векторами
- Диапазон: -1 до 1
- 1.0 = идентичные автомобили
- 0.9 = очень похожие
- 0.5 = средне похожие
- 0.0 = не похожие

### Производительность

- **Создание embeddings:** один раз для всех автомобилей (~1-2 минуты)
- **Поиск:** мгновенно (< 1 секунды)
- **Хранение:** ~5-10 МБ для 10,000 автомобилей

## Итог

**Embeddings** - это способ:
1. **Представить** каждый автомобиль как набор чисел
2. **Найти** похожие автомобили по "смыслу", а не только по точным критериям
3. **Рекомендовать** альтернативы на основе похожести
4. **Искать** даже когда запрос нечеткий или неточный

Это дополняет SPARQL запросы, добавляя "интеллектуальный" поиск по похожести!

