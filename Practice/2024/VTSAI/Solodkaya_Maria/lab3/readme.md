# Лабораторная работа 3

Выполнили:
* Полежаева Евгения (P4240)
* Солодкая Мария (P4240)

### Discount factor
Discount factor - это параметр, используемый в теории управления и обучении с подкреплением для оценки стоимости будущих вознаграждений. Он обозначается символом  γ  (гамма).

В контексте задачи обучения с подкреплением, такой как у DQN алгоритма, фактор дисконтирования применяется к будущим вознаграждениям, чтобы учесть уменьшение их значения с течением времени. Фактор дисконтирования позволяет агенту принимать во внимание не только мгновенные вознаграждения, но и будущие вознаграждения, приводя к более долгосрочной стратегии.

Фактор дисконтирования имеет важное значение при принятии решений в условиях неопределенности, где агенту нужно учитывать как мгновенные, так и будущие вознаграждения, с учетом их временного удаления. Выбор подходящего значения для фактора дисконтирования может влиять на стратегии обучения.

### Long-term и Short-term стратегия
Фактор дисконтирования оказывает сильное влияние на долгосрочность стратегии. В контексте обучения с подкреплением и стратегий агента, термины "краткосрочные" и "долгосрочные" относятся к временным характеристикам принятия решений агентом.

### Краткосрочные стратегии:
Агент, придерживающийся краткосрочной стратегии, ориентируется в основном на текущую информацию и мгновенные вознаграждения. Такой агент может принимать решения, которые приносят максимальное мгновенное вознаграждение, не уделяя большого внимания будущим шагам. Такой агент может принимать решения, которые приносят максимальное мгновенное вознаграждение, не уделяя большого внимания будущим шагам.

### Долгосрочные стратегии:
Агент, придерживающийся долгосрочной стратегии, учитывает будущие вознаграждения и последствия своих действий на протяжении более длительного времени. Такой агент может предпочесть действия, которые могут не приносить максимальное мгновенное вознаграждение, но могут способствовать достижению более высоких наград в будущем.

Когда говорят о краткосрочных или долгосрочных стратегиях в контексте обучения с подкреплением, обычно имеется в виду, как агент принимает решения, оптимизируя сумму будущих вознаграждений. Фактор дисконтирования γ в уравнении обучения с подкреплением регулирует степень учета будущих вознаграждений, и, таким образом, влияет на то, насколько агент ориентирован на краткосрочные или долгосрочные перспективы.

### Метрики для оценки модели
В данной работе мы рассмотрим некоторые метрики, которые могут быть использованы для оценки обучения модели. Аналогично первой лабораторной работы мы будем решать задачу в окружении CartPole-v1, а в качестве модели используем уже знакомый DQN. При этом мы обучим модель несколько разных с разным параметром Discount factor.

Для оценки модели мы рассмотрели следущие метрики:
* Q-values, их поведение и сходимость.
* Средняя награда за эпизод.
* Время затрачиваемое на обучение модели.

## Среда:

[Lunar Launder](https://gymnasium.farama.org/environments/box2d/lunar_lander/)

Эта среда представляет собой классическую задачу оптимизации траектории ракеты.

Доступны четыре отдельных действия:

* 0: ничего не делать
* 1: сработал левый двигатель ориентации
* 2: запуск главного двигателя
* 3: включить двигатель правильной ориентации

Посадочный модуль стартует из верхнего центра обзорного экрана со случайной начальной силой, приложенной к его центру масс.

## Выводы:

Исследован параметр Discount factor, используемый в теории управления и обучения с подкреплением для оценки стоимости будущих вознаграждений.
1. Установлены зависимости и импортированы необходимые пакеты и библиотеки.
2. Создана функция для извлечения значений из q-сети.
3. Создана функция для составления графика по значениям.
4. Создано окружение, модель, проведено обучение модели, её оценка до и после обучения, а также измерение времени обучения.
5. Создана функция для вычисления Q-values для некоторого набора предсказаний модели.
6. Проведение экспериментов с discount factor, discount_factors = [0.01,0.5,0.99].
