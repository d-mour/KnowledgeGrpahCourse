# Проблемы с обучением и их решения

## Обнаруженные проблемы

### 1. Loss растет вместо уменьшения ❌

**Симптомы:**
```
Эпоха 1/150: средний loss = 2.2677
Эпоха 50/150: средний loss = 3.8533  ← РАСТЕТ!
```

**Причина:** 
- Learning rate может быть слишком большой
- Нормализация слишком агрессивная
- Градиенты нестабильны

**Решение:**
- Уменьшить learning rate (например, 0.001 вместо 0.01)
- Убрать или смягчить нормализацию после каждого обновления
- Добавить отслеживание тренда loss

### 2. Все score одинаковые ❌

**Симптомы:**
```
Лучший score: -18.5482
Худший score: -18.5482  ← ОДИНАКОВЫЕ!
```

**Причина:**
- Embeddings не обучаются (слишком сильная нормализация)
- Модель "застряла" в локальном минимуме
- Все векторы стали одинаковыми

**Решение:**
- Убрать нормализацию после каждого обновления
- Использовать только мягкую нормализацию (если норма > 1.0)
- Увеличить learning rate или использовать адаптивный (Adam)

### 3. Правильные связи хуже неправильных ❌

**Симптомы:**
```
Средний score ПРАВИЛЬНЫХ связей: -20.5477
Средний score НЕПРАВИЛЬНЫХ связей: -18.5480  ← ХУЖЕ!
```

**Причина:**
- Модель не обучилась правильно
- Loss растет, значит обучение идет неправильно
- Embeddings не отражают структуру графа

**Решение:**
- Переобучить модель с исправленными параметрами
- Проверить правильность извлечения триплетов
- Убедиться, что направление связей правильное

## Исправления в коде

### 1. Мягкая нормализация

**Было:**
```python
# Нормализация после каждого обновления
self.entity_embeddings[h] = self.entity_embeddings[h] / max(1.0, np.linalg.norm(...))
```

**Стало:**
```python
# Мягкая нормализация (только если норма > 1.0)
h_norm = np.linalg.norm(self.entity_embeddings[h])
if h_norm > 1.0:
    self.entity_embeddings[h] = self.entity_embeddings[h] / h_norm
```

### 2. Отслеживание тренда loss

Добавлено отслеживание лучшего loss и предупреждения если loss растет.

### 3. Улучшенная проверка неправильных связей

Теперь проверяем связи, которые точно не существуют в графе.

## Рекомендации

### Если loss растет:

1. **Уменьшить learning rate:**
   ```python
   learning_rate = 0.001  # вместо 0.01
   ```

2. **Увеличить margin:**
   ```python
   margin = 2.0  # вместо 1.0
   ```

3. **Использовать меньше эпох с проверкой:**
   - Обучайте по 10 эпох
   - Проверяйте loss
   - Если растет - останавливайтесь

### Если все score одинаковые:

1. **Убрать нормализацию:**
   - Комментируйте строки с нормализацией
   - Обучите модель
   - Проверьте результаты

2. **Использовать другую инициализацию:**
   ```python
   # Вместо нормализации сразу
   self.entity_embeddings = np.random.normal(0, 0.1, (num_entities, embedding_dim))
   ```

### Если правильные хуже неправильных:

1. **Проверить направление связей:**
   - Убедитесь, что триплеты извлекаются правильно
   - Проверьте, что (vehicle, MadeBy, manufacturer) а не наоборот

2. **Переобучить с нуля:**
   ```bash
   python create_kg_embeddings.py --epochs 200 --dim 64
   ```

## Альтернативные решения

Если проблемы продолжаются, рассмотрите:

1. **Использовать готовую библиотеку:**
   - PyKEEN (https://github.com/pykeen/pykeen)
   - AmpliGraph (https://github.com/Accenture/AmpliGraph)

2. **Попробовать другую модель:**
   - DistMult (проще чем TransE)
   - ComplEx (лучше для симметричных отношений)

3. **Упростить задачу:**
   - Обучать только на одном типе отношений
   - Использовать меньше сущностей для начала

